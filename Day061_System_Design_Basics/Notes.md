# ðŸ§  Day 61: System Design Basics â€” Scalability, Latency, and Throughput

## What is System Design?
System Design is about planning **how system components work together efficiently** â€” databases, APIs, pipelines, caches, and storage.  
It ensures a system is **reliable, scalable, and high-performing** when data and users grow.

---

## âš™ï¸ Scalability
**Definition:** Ability of a system to handle **increased load (data, users, or requests)** without breaking.

**Where itâ€™s used:**
- Expanding Kafka topics for higher message volume  
- Scaling Databricks clusters  
- Sharding databases for user data  

**Why used:** To grow smoothly as business or traffic increases.  

**Coding:** Usually configuration-level, but you design code (partitioning, parallelism) to support scaling.  

### ðŸ”‘ Keywords
| Keyword | One-line Meaning |
|----------|------------------|
| **Horizontal Scaling** | Add more machines to share the load. |
| **Vertical Scaling** | Upgrade one machineâ€™s CPU/RAM. |
| **Load Balancer** | Distributes traffic evenly across servers. |
| **Partitioning** | Divide data into smaller chunks for parallel work. |
| **Replication** | Keep multiple data copies for reliability. |
| **Elasticity** | Auto-scale up or down based on usage. |

---

## âš¡ Latency
**Definition:** The time delay between sending a request and receiving a response â€” â€œhow fast it reacts.â€

**Where itâ€™s used:**
- Streaming pipelines  
- Database query response  
- Real-time dashboards  

**Why used:** Ensures **real-time responsiveness** for users or analytics.  

**Coding:** Optimize using caching (Redis), async calls, and faster I/O.

### ðŸ”‘ Keywords
| Keyword | One-line Meaning |
|----------|------------------|
| **Response Time** | Time from request to response. |
| **Network Delay** | Time data travels over the network. |
| **Caching** | Store data temporarily for faster reuse. |
| **Asynchronous** | Run tasks without waiting. |
| **Real-Time** | Process data instantly. |
| **Low-Latency** | Millisecond-level fast response. |

---

## ðŸ“ˆ Throughput
**Definition:** Amount of data or work processed per unit time â€” â€œhow much it handles per second.â€

**Where itâ€™s used:**
- Kafka â†’ Messages per second  
- Spark â†’ Rows transformed per minute  
- Databases â†’ Queries per second  

**Why used:** Measures systemâ€™s efficiency under load.

**Coding:** Tune parallelism, batch size, and partition count.

### ðŸ”‘ Keywords
| Keyword | One-line Meaning |
|----------|------------------|
| **Requests/sec** | Number of API calls handled per second. |
| **Messages/sec** | Kafka messages processed per second. |
| **Batch Size** | Records processed together in one batch. |
| **Parallelism** | Running multiple tasks simultaneously. |
| **Throughput Optimization** | Designing to handle more data faster. |

---

## ðŸ’¡ Real-world Example
**E-commerce Clickstream Pipeline:**
1. User clicks generate Kafka events.  
2. Spark Streaming processes them in near real-time.  
3. Results stored in Azure Synapse for dashboards.  

| Concept | Example | Goal |
|----------|----------|------|
| Scalability | Add Spark executors or Kafka partitions | Handle more users |
| Latency | Minimize delay to update dashboards | Real-time data |
| Throughput | Increase processed messages/sec | Efficiency |

---

ðŸ§  **Memory Hack**
> **Scalability â†’** Can it grow?  
> **Latency â†’** How fast?  
> **Throughput â†’** How much per second?
